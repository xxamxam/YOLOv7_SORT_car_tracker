{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bound-bibliography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "IDetect.fuse\n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from object_tracking import Detector, YOLOv7_track\n",
    "\n",
    "#создается детектор\n",
    "detector = Detector(classes = [0,1,2,3,4,5], use_gpu = True)\n",
    "# и к нему подгружаются веса\n",
    "detector.load_model(\"./weights/best-tiny-200.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "affiliated-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаем трекер работающий на SORT и передаем ему веса\n",
    "tracker = YOLOv7_track(detector=detector, use_cuda =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "broad-anthropology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0) normal:mp4@256x144\n",
      "1) normal:mp4@426x240\n",
      "2) normal:mp4@640x360\n",
      "3) normal:mp4@854x480\n",
      "4) normal:mp4@1280x720\n",
      "5) normal:mp4@1920x1080\n",
      "выберите номер источника:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilgam/.local/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2895.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 вошел в кадр в 2022-09-02 19:12:25.479843. Номер кадра : 13\n",
      "1.0 вышел из кадра в 2022-09-02 19:12:39.361514. Номер кадра : 13\n",
      "2.0 вошел в кадр в 2022-09-02 19:12:39.361610. Номер кадра : 160\n",
      "2.0 вышел из кадра в 2022-09-02 19:12:51.740641. Номер кадра : 167\n",
      "3.0 вошел в кадр в 2022-09-02 19:12:51.740754. Номер кадра : 289\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ilgam/iPavlov/Example.ipynb Ячейка 3\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ilgam/iPavlov/Example.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# из-за особенностей jupyter файлов чтобы остановить трекинг вам потребуется убить ядро\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ilgam/iPavlov/Example.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# в примере из test.py для завершения текинга нужно только остановить запущенный процесс\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ilgam/iPavlov/Example.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# запустим трекинг видео/ стрима из youtube\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ilgam/iPavlov/Example.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m tracker\u001b[39m.\u001b[39;49mtrack_video(\u001b[39m\"\u001b[39;49m\u001b[39mhttps://youtu.be/C77Fddophmg\u001b[39;49m\u001b[39m\"\u001b[39;49m, output \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/iPavlov/object_tracking/bridge_wrapper.py:145\u001b[0m, in \u001b[0;36mYOLOv7_track.track_video\u001b[0;34m(self, video, output, skip_frames, show_live, count_objects, verbose)\u001b[0m\n\u001b[1;32m    143\u001b[0m start_time \u001b[39m=\u001b[39m time()\n\u001b[1;32m    144\u001b[0m thr \u001b[39m=\u001b[39m Thread_convey([detector, tracker])\n\u001b[0;32m--> 145\u001b[0m frames \u001b[39m=\u001b[39m thr\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m    146\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtracked \u001b[39m\u001b[39m{\u001b[39;00mframes\u001b[39m}\u001b[39;00m\u001b[39m frames in \u001b[39m\u001b[39m{\u001b[39;00mtime() \u001b[39m-\u001b[39m start_time\u001b[39m}\u001b[39;00m\u001b[39m seconds, or \u001b[39m\u001b[39m{\u001b[39;00mframes \u001b[39m/\u001b[39m (time() \u001b[39m-\u001b[39m start_time)\u001b[39m}\u001b[39;00m\u001b[39m fps\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/iPavlov/object_tracking/threads.py:87\u001b[0m, in \u001b[0;36mThread_convey.start\u001b[0;34m(self, join)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39m# функция выхода из трекера\u001b[39;00m\n\u001b[1;32m     86\u001b[0m         \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m             \u001b[39mif\u001b[39;00m hearEnter():\n\u001b[1;32m     88\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mthreads[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mstop()\n\u001b[1;32m     89\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mthreads[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mis_alive():\n",
      "File \u001b[0;32m~/iPavlov/object_tracking/threads.py:79\u001b[0m, in \u001b[0;36mThread_convey.start.<locals>.hearEnter\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhearEnter\u001b[39m():\n\u001b[0;32m---> 79\u001b[0m     i, o, e \u001b[39m=\u001b[39m select\u001b[39m.\u001b[39;49mselect([sys\u001b[39m.\u001b[39;49mstdin], [], [], \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     80\u001b[0m     \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m i:\n\u001b[1;32m     81\u001b[0m         \u001b[39mif\u001b[39;00m s \u001b[39m==\u001b[39m sys\u001b[39m.\u001b[39mstdin:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# из-за особенностей jupyter файлов чтобы остановить трекинг вам потребуется убить ядро\n",
    "# в примере из test.py для завершения текинга нужно только остановить запущенный процесс\n",
    "# запустим трекинг видео/ стрима из youtube\n",
    "tracker.track_video(\"https://youtu.be/C77Fddophmg\", output = None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# аналогично можно запустить  трекинг записанного видео видео передав в качестве аргумента локальный адрес видео\n",
    "# если в output указать директорию с именем файла, то там запишется видеотрекинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтобы добавить действия в начале или в конце детекции отредактируйте файл notify_tracker.py "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
